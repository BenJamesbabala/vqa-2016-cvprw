<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Visual Question Answering for CVPR 2016 by imatge-upc</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Visual Question Answering for CVPR 2016</h1>
      <h2 class="project-tagline">UPC-UB team</h2>
      <a href="https://github.com/imatge-upc/vqa-2016" class="btn">View on GitHub</a>
      <a href="https://github.com/imatge-upc/vqa-2016/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/imatge-upc/vqa-2016/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>This is the project page of the UPC-UB team participating in the <a href="http://www.visualqa.org/challenge.html">VQA challenge</a> for CVPR 2016. Details of the proposed solutions will be posted after the deadline.</p>

<p>Main contributor: Issey Masuda
Advisors: Santi Pascual, Marc Bolaños and Xavier Giro-i-Nieto
Institutions: <a href="http://www.upc.edu">Universitat Politecnica de Catalunya</a> and <a href="http://www.ub.edu">Universitat de Barcelona</a>.</p>

<h2>
<a id="related-work" class="anchor" href="#related-work" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related work</h2>

<ul>
<li>Ren, Mengye, Ryan Kiros, and Richard Zemel. <a href="http://papers.nips.cc/paper/5640-exploring-models-and-data-for-image-question-answering">"Exploring models and data for image question answering."</a> In Advances in Neural Information Processing Systems, pp. 2935-2943. 2015. <a href="http://gitxiv.com/posts/6pFP3b8gqxWZdBfjf/exploring-models-and-data-for-image-question-answering">[code]</a>
</li>
<li>Antol, Stanislaw, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Antol_VQA_Visual_Question_ICCV_2015_paper.html">"VQA: Visual question answering."</a> In Proceedings of the IEEE International Conference on Computer Vision, pp. 2425-2433. 2015. <a href="http://gitxiv.com/posts/zDn9kkA66FnG3ZuKz/vqa-visual-question-answering">[code]</a>
</li>
<li> Zhu, Yuke, Oliver Groth, Michael Bernstein, and Li Fei-Fei. <a href="http://web.stanford.edu/%7Eyukez/visual7w.html">"Visual7W: Grounded Question Answering in Images."</a> arXiv preprint arXiv:1511.03416 (2015).</li>
<li> Malinowski, Mateusz, Marcus Rohrbach, and Mario Fritz. <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.html">"Ask your neurons: A neural-based approach to answering questions about images."</a> In Proceedings of the IEEE International Conference on Computer Vision, pp. 1-9. 2015. <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/">[code]</a>
</li>
<li> Xiong, Caiming, Stephen Merity, and Richard Socher. <a href="http://arxiv.org/abs/1603.01417">"Dynamic Memory Networks for Visual and Textual Question Answering."</a> arXiv preprint arXiv:1603.01417 (2016). <a href="https://news.ycombinator.com/item?id=11237125">[discussion]</a> <a href="http://www.nytimes.com/2016/03/07/technology/taking-baby-steps-toward-software-that-reasons-like-humans.html?_r=0">[Thew New York Times]</a>
</li>
<li>Serban, Iulian Vlad, Alberto García-Durán, Caglar Gulcehre, Sungjin Ahn, Sarath Chandar, Aaron Courville, and Yoshua Bengio. <a href="http://arxiv.org/abs/1603.06807">"Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus."</a> arXiv preprint arXiv:1603.06807 (2016). <a href="http://agarciaduran.org/">[dataset]</a>
</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/imatge-upc/vqa-2016">Visual Question Answering for CVPR 2016</a> is maintained by <a href="https://github.com/imatge-upc">imatge-upc</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
